{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting machine learning benchmark datasets\n",
    "\n",
    "[Alexander L. Hayes](https://hayesall.com): *Ph.D. Student, Indiana University*.\n",
    "\n",
    "**Abstract**: Most benchmark machine learning datasets have a *vector-based representation*, where we have a single type of object (people, images, houses) and we learn an *attribute* of those objects (disease risk, cat/dog, median price). This tutorial bridges the gap between vector-based machine learning and relational machine learning, and shows how to view the former in terms of the latter.\n",
    "\n",
    "Examples in this notebook are provided as documentation, and are available under the terms of the Apache 2.0 License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relational_datasets.convert import from_numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "\n",
    "We're in a binary classification setting when the target array `y` contains 0/1 integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, modes = from_numpy(\n",
    "    np.array([[0, 1, 1], [0, 1, 2], [1, 2, 2]]),\n",
    "    np.array([0, 0, 1]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v4(id3).']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v4(id1).', 'v4(id2).']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are learning from a collection of **one type of object**. Since there is only one type of object, we can enumerate them with an `id`.\n",
    "\n",
    "The *positive examples* show that the object with `id3` is a positive instance of a class, and the *negative examples* show that objects `id1` and `id2` are not instances of this class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v1(id1,0).',\n",
       " 'v1(id2,0).',\n",
       " 'v1(id3,1).',\n",
       " 'v2(id1,1).',\n",
       " 'v2(id2,1).',\n",
       " 'v2(id3,2).',\n",
       " 'v3(id1,1).',\n",
       " 'v3(id2,2).',\n",
       " 'v3(id3,2).']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Modes* are a type of *background knowledge* that show up in the fields of *Inductive Logic Programming* and *Statistical Relational Learning*. A full discussion of them is not feasible here, but briefly: modes provide (1) *type information* and help (2) *constrain the search space* during learning.\n",
    "\n",
    "> *Alexander did write a [slightly longer discussion about modes](https://hayesall.com/publications/construction-background-knowledge/) to accompany a Knowledge Capture article.*\n",
    "> \n",
    "> ILP/SRL can also be highly sensitive to this type of background knowledge. Andrew Cropper, Sebastijan Dumančić, and Stephen H. Muggleton include a more general treatment of refining and learning background knowledge in [their 2020 IJCAI article](https://www.ijcai.org/proceedings/2020/0673.pdf).\n",
    "\n",
    "Modes can be set automatically in the propositional setting. The ones below say: \"When learning about a binary attribute `v4`, we will bind the `id` of an object to a specific instances (`id1`, `id2`, `id3`), and then learn about it with respect to specific values (`#`) of its attributes `v1`, `v2`, and `v3`.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v1(+id,#varv1).', 'v2(+id,#varv2).', 'v3(+id,#varv3).', 'v4(+id).']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "When `y` contains floating point numbers we're in a regression setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, modes = from_numpy(\n",
    "    np.array([[0, 1, 1], [0, 1, 2], [1, 2, 2]]),\n",
    "    np.array([1.1, 0.9, 2.5]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We represent this by marking all objects as \"positive examples,\" but we want to learn about a *continuous value.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['regressionExample(v4(id1),1.1).',\n",
       " 'regressionExample(v4(id2),0.9).',\n",
       " 'regressionExample(v4(id3),2.5).']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['v1(id1,0).',\n",
       " 'v1(id2,0).',\n",
       " 'v1(id3,1).',\n",
       " 'v2(id1,1).',\n",
       " 'v2(id2,1).',\n",
       " 'v2(id3,2).',\n",
       " 'v3(id1,1).',\n",
       " 'v3(id2,2).',\n",
       " 'v3(id3,2).']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.facts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Side Note*: Naming Variables\n",
    "\n",
    "From the previous examples, we saw that names for the variables and targets were automatically assigned (with the last value `v4` being the target).\n",
    "\n",
    "The `from_numpy` function returns a tuple containing a `RelationalDataset` and a list of strings containing the modes. If an additional list of strings is passed, then those are used when converting the arrays.\n",
    "\n",
    "Here we invent a dataset where each `id` represents a person, and we want to learn about their risk for a condition in based on their age, BMI, and coronary artery calcification (cac) levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1, 2], [1, 1, 0], [0, 1, 0], [1, 1, 1], [0, 1, 1]])\n",
    "y = np.array([0, 0, 1, 1, 0])\n",
    "\n",
    "data, modes = from_numpy(\n",
    "    X,\n",
    "    y,\n",
    "    [\"age\", \"bmi\", \"cac\", \"highrisk\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['highrisk(id3).', 'highrisk(id4).']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['highrisk(id1).', 'highrisk(id2).', 'highrisk(id5).']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age(id1,1).',\n",
       " 'age(id2,1).',\n",
       " 'age(id3,0).',\n",
       " 'age(id4,1).',\n",
       " 'age(id5,0).',\n",
       " 'bmi(id1,1).',\n",
       " 'bmi(id2,1).',\n",
       " 'bmi(id3,1).',\n",
       " 'bmi(id4,1).',\n",
       " 'bmi(id5,1).',\n",
       " 'cac(id1,2).',\n",
       " 'cac(id2,0).',\n",
       " 'cac(id3,0).',\n",
       " 'cac(id4,1).',\n",
       " 'cac(id5,1).']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age(+id,#varage).',\n",
       " 'bmi(+id,#varbmi).',\n",
       " 'cac(+id,#varcac).',\n",
       " 'highrisk(+id).']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worked example with scikit-learn's `load_breast_cancer`\n",
    "\n",
    "[`load_breast_cancer`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) is based on the <a href=\"https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\">Breast Cancer Wisconsin dataset</a>.\n",
    "\n",
    "Here we: (**1**) load the data and class labels, (**2**) split into training and test sets, (**3**) bin the continuous features to discrete, and (**4**) convert to the relational format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import KBinsDiscretizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Load the data, target, and variable names\n",
    "\n",
    "Invoking `load_breast_cancer` returns a dictionary-like object with keys for `.data`, `.target`, `.feature_names`, and `.target_names`. We'll use these to pull out our `X` matrix, `y` array, and variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "bc_X = breast_cancer.data\n",
    "bc_y = breast_cancer.target\n",
    "variable_names = [name.replace(\" \", \"\") for name in breast_cancer.feature_names.tolist()] + [breast_cancer.target_names[1]]\n",
    "\n",
    "bc_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meanradius',\n",
       " 'meantexture',\n",
       " 'meanperimeter',\n",
       " 'meanarea',\n",
       " 'meansmoothness',\n",
       " 'meancompactness',\n",
       " 'meanconcavity',\n",
       " 'meanconcavepoints',\n",
       " 'meansymmetry',\n",
       " 'meanfractaldimension',\n",
       " 'radiuserror',\n",
       " 'textureerror',\n",
       " 'perimetererror',\n",
       " 'areaerror',\n",
       " 'smoothnesserror',\n",
       " 'compactnesserror',\n",
       " 'concavityerror',\n",
       " 'concavepointserror',\n",
       " 'symmetryerror',\n",
       " 'fractaldimensionerror',\n",
       " 'worstradius',\n",
       " 'worsttexture',\n",
       " 'worstperimeter',\n",
       " 'worstarea',\n",
       " 'worstsmoothness',\n",
       " 'worstcompactness',\n",
       " 'worstconcavity',\n",
       " 'worstconcavepoints',\n",
       " 'worstsymmetry',\n",
       " 'worstfractaldimension',\n",
       " 'benign']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) Split out training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bc_X, bc_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) Discretize continuous features to discrete\n",
    "\n",
    "scikit-learn's [`KBinsDiscretizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html) will help us here, but we'll want an ordinal (0, 1, 2, 3, 4) encoding for our discrete features rather than the default one-hot encoding, and we need to ensure that the resulting matrices are converted back to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4, 4, ..., 4, 2, 1],\n",
       "       [2, 1, 2, ..., 0, 1, 2],\n",
       "       [4, 3, 4, ..., 4, 2, 3],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 2, 0, 0],\n",
       "       [1, 3, 1, ..., 1, 1, 3],\n",
       "       [1, 0, 1, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disc = KBinsDiscretizer(n_bins=5, encode=\"ordinal\")\n",
    "X_train = disc.fit_transform(X_train)\n",
    "X_test = disc.transform(X_test)\n",
    "X_train = X_train.astype(int)\n",
    "X_test = X_test.astype(int)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) Convert arrays to `RelationalDataset`\n",
    "\n",
    "Finally, let's convert our training and test folds into `RelationalDatasets` and `modes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meanradius(+id,#varmeanradius).',\n",
       " 'meantexture(+id,#varmeantexture).',\n",
       " 'meanperimeter(+id,#varmeanperimeter).',\n",
       " 'meanarea(+id,#varmeanarea).',\n",
       " 'meansmoothness(+id,#varmeansmoothness).',\n",
       " 'meancompactness(+id,#varmeancompactness).',\n",
       " 'meanconcavity(+id,#varmeanconcavity).',\n",
       " 'meanconcavepoints(+id,#varmeanconcavepoints).',\n",
       " 'meansymmetry(+id,#varmeansymmetry).',\n",
       " 'meanfractaldimension(+id,#varmeanfractaldimension).',\n",
       " 'radiuserror(+id,#varradiuserror).',\n",
       " 'textureerror(+id,#vartextureerror).',\n",
       " 'perimetererror(+id,#varperimetererror).',\n",
       " 'areaerror(+id,#varareaerror).',\n",
       " 'smoothnesserror(+id,#varsmoothnesserror).',\n",
       " 'compactnesserror(+id,#varcompactnesserror).',\n",
       " 'concavityerror(+id,#varconcavityerror).',\n",
       " 'concavepointserror(+id,#varconcavepointserror).',\n",
       " 'symmetryerror(+id,#varsymmetryerror).',\n",
       " 'fractaldimensionerror(+id,#varfractaldimensionerror).',\n",
       " 'worstradius(+id,#varworstradius).',\n",
       " 'worsttexture(+id,#varworsttexture).',\n",
       " 'worstperimeter(+id,#varworstperimeter).',\n",
       " 'worstarea(+id,#varworstarea).',\n",
       " 'worstsmoothness(+id,#varworstsmoothness).',\n",
       " 'worstcompactness(+id,#varworstcompactness).',\n",
       " 'worstconcavity(+id,#varworstconcavity).',\n",
       " 'worstconcavepoints(+id,#varworstconcavepoints).',\n",
       " 'worstsymmetry(+id,#varworstsymmetry).',\n",
       " 'worstfractaldimension(+id,#varworstfractaldimension).',\n",
       " 'benign(+id).']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_train, bc_modes = from_numpy(X_train, y_train, names=variable_names)\n",
    "bc_test, _ = from_numpy(X_test, y_test, names=variable_names)\n",
    "\n",
    "bc_modes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
